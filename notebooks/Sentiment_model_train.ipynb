{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Comments analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "04278307"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Applications/anaconda3/lib/python3.11/site-packages (4.42.3)\r\n",
      "Requirement already satisfied: torch in /Applications/anaconda3/lib/python3.11/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (0.23.4)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\r\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Applications/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Applications/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /Applications/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\r\n",
      "Requirement already satisfied: networkx in /Applications/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Applications/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Applications/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Applications/anaconda3/lib/python3.11/site-packages (4.42.3)\r\n",
      "Requirement already satisfied: datasets in /Applications/anaconda3/lib/python3.11/site-packages (2.12.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Applications/anaconda3/lib/python3.11/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: torch in /Applications/anaconda3/lib/python3.11/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (0.23.4)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\r\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Applications/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Applications/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Applications/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from datasets) (11.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Applications/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /Applications/anaconda3/lib/python3.11/site-packages (from datasets) (1.5.3)\r\n",
      "Requirement already satisfied: xxhash in /Applications/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: multiprocess in /Applications/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\r\n",
      "Requirement already satisfied: aiohttp in /Applications/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\r\n",
      "Requirement already satisfied: responses<0.19 in /Applications/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\r\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /Applications/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.26.16)\r\n",
      "Requirement already satisfied: six in /Applications/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Applications/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\r\n",
      "Requirement already satisfied: sympy in /Applications/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\r\n",
      "Requirement already satisfied: networkx in /Applications/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Applications/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Applications/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Applications/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Applications/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Applications/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Applications/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Applications/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Applications/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Applications/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Applications/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Applications/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torch\n",
    "! pip install transformers datasets scikit-learn torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:04.481487Z",
     "start_time": "2025-09-09T14:21:02.684577Z"
    }
   },
   "id": "2c6f6bbac7aa2878"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from collections import Counter\n",
    "# import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import TextClassificationPipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "# from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-13T08:57:37.107722Z",
     "start_time": "2025-09-13T08:57:37.106840Z"
    }
   },
   "id": "fa744d4d96ed7f94"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       post_id                                       comment_text  \\\n0      21390.0  there will be no freedom, first trump is prepa...   \n1      21390.0  i think us and ukraine could have a very good ...   \n2      21390.0  ти антисеміт!!!ти гітлера підтримуєш???\\nце як...   \n3      21390.0  i think same goes for israel. lots of american...   \n4      21390.0  тобто не посилати гроші в ізраїль, бо бідним а...   \n...        ...                                                ...   \n32885  93453.0  земли - россии 🇷🇺\\nдолги - европе 🇪🇺\\nденьги -...   \n32886  93453.0  быть друзьями россии и быть с россией на равны...   \n32887  93453.0  50%? америкосы заберут 150,в этом сомневаться ...   \n32888  93453.0                                  доня агент кремля   \n32889  93453.0  ого, пареце, что сша и украина до сих пор не м...   \n\n              comment_date  comment_user_id channel_orientation  \\\n0      2025-03-02 10:28:41     7.868621e+09       pro-ukrainian   \n1      2025-03-02 10:27:22     8.170125e+09       pro-ukrainian   \n2      2025-03-02 10:10:15     7.868621e+09       pro-ukrainian   \n3      2025-03-02 10:09:37     8.170125e+09       pro-ukrainian   \n4      2025-03-02 10:08:18     7.868621e+09       pro-ukrainian   \n...                    ...              ...                 ...   \n32885  2025-02-26 15:41:55     5.057871e+08         pro-russian   \n32886  2025-02-26 15:41:24     5.203758e+09         pro-russian   \n32887  2025-02-26 15:39:35     5.169864e+09         pro-russian   \n32888  2025-02-26 15:38:56     2.033804e+09         pro-russian   \n32889  2025-02-26 15:38:55     7.454295e+09         pro-russian   \n\n                   source_file comment_language  \\\n0      data/ua/Comments_ds.csv               en   \n1      data/ua/Comments_ds.csv               en   \n2      data/ua/Comments_ds.csv               uk   \n3      data/ua/Comments_ds.csv               en   \n4      data/ua/Comments_ds.csv               uk   \n...                        ...              ...   \n32885  data/ru/Comments_re.csv               ru   \n32886  data/ru/Comments_re.csv               ru   \n32887  data/ru/Comments_re.csv               ru   \n32888  data/ru/Comments_re.csv               ru   \n32889  data/ru/Comments_re.csv               ru   \n\n                                        text_transformed                 date  \\\n0      there will be no freedom, first trump is prepa...  2025-02-28 20:20:56   \n1      i think us and ukraine could have a very good ...  2025-02-28 20:20:56   \n2      ти антисеміт!!!ти гітлера підтримуєш???\\nце як...  2025-02-28 20:20:56   \n3      i think same goes for israel. lots of american...  2025-02-28 20:20:56   \n4      тобто не посилати гроші в ізраїль, бо бідним а...  2025-02-28 20:20:56   \n...                                                  ...                  ...   \n32885  земли - россии :Russia \\nдолги - европе :Europ...  2025-02-26 15:37:46   \n32886  быть друзьями россии и быть с россией на равны...  2025-02-26 15:37:46   \n32887  50%? америкосы заберут 150,в этом сомневаться ...  2025-02-26 15:37:46   \n32888                                  доня агент кремля  2025-02-26 15:37:46   \n32889  ого, пареце, что сша и украина до сих пор не м...  2025-02-26 15:37:46   \n\n        views  forwards     channel_id  channel_name source           bloc  \\\n0      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n1      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n2      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n3      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n4      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n...       ...       ...            ...           ...    ...            ...   \n32885  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n32886  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n32887  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n32888  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n32889  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n\n      period  post_age_at_comment  \n0       post            38.129167  \n1       post            38.107222  \n2       post            37.821944  \n3       post            37.811389  \n4       post            37.789444  \n...      ...                  ...  \n32885    pre             0.069167  \n32886    pre             0.060556  \n32887    pre             0.030278  \n32888    pre             0.019444  \n32889    pre             0.019167  \n\n[32890 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>post_id</th>\n      <th>comment_text</th>\n      <th>comment_date</th>\n      <th>comment_user_id</th>\n      <th>channel_orientation</th>\n      <th>source_file</th>\n      <th>comment_language</th>\n      <th>text_transformed</th>\n      <th>date</th>\n      <th>views</th>\n      <th>forwards</th>\n      <th>channel_id</th>\n      <th>channel_name</th>\n      <th>source</th>\n      <th>bloc</th>\n      <th>period</th>\n      <th>post_age_at_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21390.0</td>\n      <td>there will be no freedom, first trump is prepa...</td>\n      <td>2025-03-02 10:28:41</td>\n      <td>7.868621e+09</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>en</td>\n      <td>there will be no freedom, first trump is prepa...</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>38.129167</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21390.0</td>\n      <td>i think us and ukraine could have a very good ...</td>\n      <td>2025-03-02 10:27:22</td>\n      <td>8.170125e+09</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>en</td>\n      <td>i think us and ukraine could have a very good ...</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>38.107222</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21390.0</td>\n      <td>ти антисеміт!!!ти гітлера підтримуєш???\\nце як...</td>\n      <td>2025-03-02 10:10:15</td>\n      <td>7.868621e+09</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>uk</td>\n      <td>ти антисеміт!!!ти гітлера підтримуєш???\\nце як...</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>37.821944</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21390.0</td>\n      <td>i think same goes for israel. lots of american...</td>\n      <td>2025-03-02 10:09:37</td>\n      <td>8.170125e+09</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>en</td>\n      <td>i think same goes for israel. lots of american...</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>37.811389</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21390.0</td>\n      <td>тобто не посилати гроші в ізраїль, бо бідним а...</td>\n      <td>2025-03-02 10:08:18</td>\n      <td>7.868621e+09</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>uk</td>\n      <td>тобто не посилати гроші в ізраїль, бо бідним а...</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>37.789444</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32885</th>\n      <td>93453.0</td>\n      <td>земли - россии 🇷🇺\\nдолги - европе 🇪🇺\\nденьги -...</td>\n      <td>2025-02-26 15:41:55</td>\n      <td>5.057871e+08</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>земли - россии :Russia \\nдолги - европе :Europ...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.069167</td>\n    </tr>\n    <tr>\n      <th>32886</th>\n      <td>93453.0</td>\n      <td>быть друзьями россии и быть с россией на равны...</td>\n      <td>2025-02-26 15:41:24</td>\n      <td>5.203758e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>быть друзьями россии и быть с россией на равны...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.060556</td>\n    </tr>\n    <tr>\n      <th>32887</th>\n      <td>93453.0</td>\n      <td>50%? америкосы заберут 150,в этом сомневаться ...</td>\n      <td>2025-02-26 15:39:35</td>\n      <td>5.169864e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>50%? америкосы заберут 150,в этом сомневаться ...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.030278</td>\n    </tr>\n    <tr>\n      <th>32888</th>\n      <td>93453.0</td>\n      <td>доня агент кремля</td>\n      <td>2025-02-26 15:38:56</td>\n      <td>2.033804e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>доня агент кремля</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.019444</td>\n    </tr>\n    <tr>\n      <th>32889</th>\n      <td>93453.0</td>\n      <td>ого, пареце, что сша и украина до сих пор не м...</td>\n      <td>2025-02-26 15:38:55</td>\n      <td>7.454295e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>ого, пареце, что сша и украина до сих пор не м...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.019167</td>\n    </tr>\n  </tbody>\n</table>\n<p>32890 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"data/data_clean/Comments_clean.csv\")\n",
    "df_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:19.899937Z",
     "start_time": "2025-09-09T13:57:19.442216Z"
    }
   },
   "id": "7ea7f6420a2a805c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trying out russian and ukrianian sentiment models "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0092a202f147938"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE | так можно говорить с президентом сша. один раз!\n",
      "POSITIVE | трамп говорит \"stupid president\" не на зелю, а на байдена. прислушайтесь. трамп говорит: \"мы дали вам благодаря тому тупому президенту...\"\n",
      "POSITIVE | его подпись под сделкой фикция.зелибоба никто.\n",
      "POSITIVE | зеля как на оскаре, благодарю америку, маму, папу, кошку, мышку...:face_with_tears_of_joy :clown_face \n",
      "NEGATIVE | и потом кто-то на расширенной конференции будет руками разводить- ой нас опять объебали....\n",
      "POSITIVE | обосрался - обтекай! а лучше застрелись.\n",
      "NEGATIVE | ждём когда назовет нарколыгу террористом и диктатором. и приравняет к бен ладену или саддаму. и скажет, что те,  кто его поддерживают, будут считаться поддерживающие терроризм. и соответствующие санкции и прочие суды.\n",
      "хотя, это надо было уже давно сказать, только нашим руководителям.\n",
      "NEGATIVE | без твоих советов взрослые дяди разберутся\n",
      "NEGATIVE | есть мнение насчет заявления трампа на прошедшей встрече с британцем, когда он отказался от своих слов, что назвал зеленского диктатором. \n",
      " похоже, то был сарказм. типо \"что серьезно? назвал диктатором?)!\" \n",
      "читать с правильной интонацией :grinning_face_with_sweat \n",
      "NEGATIVE | отделался, а теперь нализывает.\n",
      "NEUTRAL  | __либо дадим им биться и посмотрим, что произойдет»,__\n",
      "так сказал трампуська, смотри выше\n",
      "да и вообще на х** его слушать \n",
      "бред старческий\n",
      "NEGATIVE | они нам ещё и за штаты ответят!\n",
      "NEUTRAL  | ну конечно он раз психовал из за вранья трампа,трамп сказал,что потери миллион,а какой такой миллион если всего 999к где тут миллион)\n",
      "NEGATIVE | тут нато в кой-то веке что-то адекватное выдвинуло, и туту зеленский нос воротит, показывает, что он там принципиальный и крутой, но на деле же совсем обезумел, хочет полноценную войну развязать\n",
      "NEUTRAL  | сегодня лучший день\n",
      "NEUTRAL  | вот вы все ссыте зеленского ))) значит всё правильно делает . логика просто логика\n",
      "NEGATIVE | сбу , одевайте скорее наручники кокаиновой просрочке - он опять  собрался продавать народное добро !\n",
      "NEGATIVE | и единственный шанс не платить американцам - быть русскими.\n",
      "POSITIVE | новые поставки приостановили,а старые нет.и что.....трампу,по сути,нужны только залежи ископаемых,у него тут своя выгода,а оружие как поступало,так и будет поступать,даже если они что-то и подпишут.\n",
      "POSITIVE | пусть хоть старлинк отключит и разведданные и наведение остановить. больше и не надо.\n"
     ]
    }
   ],
   "source": [
    "# Loading Russian sentiment model\n",
    "model_name = \"blanchefort/rubert-base-cased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Sampling Russian comments\n",
    "sample_ru = df_all[\n",
    "    (df_all[\"comment_language\"] == \"ru\") & (df_all[\"bloc\"] == \"pro-russian\")\n",
    "    ][\"text_transformed\"].sample(20, random_state=1).tolist()\n",
    "\n",
    "\n",
    "def predict_sentiment_ru(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = torch.argmax(probs, dim=1)\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    return [labels[i] for i in predictions]\n",
    "\n",
    "\n",
    "ru_results = predict_sentiment_ru(sample_ru)\n",
    "for text, label in zip(sample_ru, ru_results):\n",
    "    print(f\"{label.upper():<8} | {text}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:24.051072Z",
     "start_time": "2025-09-09T13:57:19.908371Z"
    }
   },
   "id": "cdb02e97adeb4908"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE | немає ознак цього. це облуда. поки так.\n",
      "POSITIVE | трамп боїться путіна\n",
      "NEGATIVE | йо, є лінка на відос?\n",
      "POSITIVE | занурись у своє болото і не смерди тут шавка путінська\n",
      "POSITIVE | дуже приємно, а я думала твоя клікуха лиса голова.\n",
      "NEGATIVE | подзвони пути і скажи щоб дрони розвертав вже зараз які летять\n",
      "POSITIVE | зеленському сраку трампу треба бцло вилизувать? шоб трамп наступного ранку проснувся в іншому настрої і так само сказав як сьогодні??? то до чого б було те лизання??? а може завтра скаже шо зеленський красавчик бо зміг протистояти самому йому? у трампа 7 пʼятниць на неділю, не забувайте.\n",
      "NEGATIVE | знову  на скандал  наривається\n",
      "POSITIVE | підрило риже\n",
      "POSITIVE | хоч хтось в цьому житті за довгий час сказав америкосам що вони самовпевненні гандони без совісті і честі!\n",
      "POSITIVE | хз... тут треба було б юристами порадитись: можна було б і підписати, через пару років організувати звернення депутатів до кс, отримати висновок що угода суперечить конституції і послати амерів накуй.\n",
      "NEGATIVE | може ще кучері накрутити, бо так хоче трамп??\n",
      "POSITIVE | ой, а хто в нас такий тут в підгузки напісяв:rolling_on_the_floor_laughing \n",
      "NEGATIVE | гарантії?????\n",
      "NEGATIVE | \"всього 2%\" мені вчора в квартиру ледве не уїбало\n",
      "NEGATIVE | перекладач лайно\n",
      "POSITIVE | яка блядь неповага\n",
      "це трамп проявив неповагу і з приниження зеленського начав\n",
      "POSITIVE | це ж треба ще витримку мати. я б вже послав і поїхав би\n",
      "POSITIVE | щось знав мабуть волц,знав ,що провокація готується\n",
      "POSITIVE | якось похуй,що там кому не подобається! тримайте пане президент! слава зсу! слава україні!\n"
     ]
    }
   ],
   "source": [
    "# Trying for Ukrainian sentiment model\n",
    "model_name_ua = \"blanchefort/rubert-base-cased-sentiment\"\n",
    "tokenizer_ua = AutoTokenizer.from_pretrained(model_name_ua)\n",
    "model_ua = AutoModelForSequenceClassification.from_pretrained(model_name_ua)\n",
    "\n",
    "\n",
    "def predict_sentiment_ua(texts):\n",
    "    inputs = tokenizer_ua(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ua(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = torch.argmax(probs, dim=1)\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    return [labels[i] for i in predictions]\n",
    "\n",
    "\n",
    "# Sampling test\n",
    "sample_ukr = df_all[\n",
    "    (df_all[\"comment_language\"] == \"uk\") & (df_all[\"bloc\"] == \"pro-ukrainian\")\n",
    "    ][\"text_transformed\"].sample(20, random_state=1).tolist()\n",
    "\n",
    "ua_results = predict_sentiment_ua(sample_ukr)\n",
    "for text, label in zip(sample_ukr, ua_results):\n",
    "    print(f\"{label.upper():<8} | {text}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:29.199426Z",
     "start_time": "2025-09-09T13:57:23.909215Z"
    }
   },
   "id": "1e44c888f6ed38c8"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE | пососеш, ок?\n",
      "POSITIVE | вибачаюсь, зря биканув\n",
      "NEGATIVE | по тебе так точно, бот !)\n",
      "NEGATIVE | ну как-то так дядя.\n",
      "POSITIVE | по ходу-не понимают.\n",
      "POSITIVE | ну так бойся сука в своем болоте! ті че думал в сказку попал и все обосрались,\n",
      "POSITIVE | пиздец подкрался, в этот раз заметно\n",
      "POSITIVE | хвора людина!\n",
      "POSITIVE | китай росеи предупредил:index_pointing_up_selector ты думаешь путину позволят устроить апокалипсис? :woman_facepalming_selector ты идиот?\n",
      "NEGATIVE | дудачок он\n",
      "POSITIVE | сцить кому? мага-довбойоби навпаки, таким чином глузують\n",
      "POSITIVE | просто позоиище\n",
      "NEGATIVE | для украины очень плохо европа не потянет да им пофик они живут в мире я уверена что зеленский мог бы сесть за стол переговоров и спасти украину но не хочет правда до последнего украинца должны погибнуть понимают и хотят мира те у кого родные на фронте мы теряем каждый день людей територии разрушение территорий нужен мир что бы сохранить то что осталось\n",
      "POSITIVE | європа так за нас , как и россия \n",
      "чужими руками жар гребут. им на нас на срать как и всем.\n",
      "POSITIVE | ты такой тупой, это треш! у кацопов и спроси, зеленобот.\n",
      "NEGATIVE | американский клоун\n",
      "POSITIVE | он наркот вылез, что б мы делали без твоего тупого мнения\n",
      "POSITIVE | пока трамп 1 : 1 трамп :beaming_face_with_smiling_eyes \n",
      "POSITIVE | как они уже все заебали . дайте людям просто жить\n",
      "NEGATIVE | йдуть торги\n"
     ]
    }
   ],
   "source": [
    "# Loading public Ukrainian sentiment model\n",
    "model_name_ua = \"blanchefort/rubert-base-cased-sentiment\"\n",
    "tokenizer_ua = AutoTokenizer.from_pretrained(model_name_ua)\n",
    "model_ua = AutoModelForSequenceClassification.from_pretrained(model_name_ua)\n",
    "\n",
    "\n",
    "def predict_sentiment_ua(texts):\n",
    "    inputs = tokenizer_ua(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ua(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = torch.argmax(probs, dim=1)\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    return [labels[i] for i in predictions]\n",
    "\n",
    "\n",
    "# Sampling test\n",
    "sample_ukr = df_all[\n",
    "    (df_all[\"comment_language\"] == \"ru\") & (df_all[\"bloc\"] == \"pro-ukrainian\")\n",
    "    ][\"text_transformed\"].sample(20, random_state=1).tolist()\n",
    "\n",
    "ua_results = predict_sentiment_ua(sample_ukr)\n",
    "for text, label in zip(sample_ukr, ua_results):\n",
    "    print(f\"{label.upper():<8} | {text}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:32.925767Z",
     "start_time": "2025-09-09T13:57:29.200823Z"
    }
   },
   "id": "f4cb9460019cc4ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trying lexicon-based sentiment analysis for Ukrainian "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1058b4ecdf91c652"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word', 'pos_neg']\n"
     ]
    }
   ],
   "source": [
    "# Loading the sentiment lexicon\n",
    "lexicon_df = pd.read_csv(\"data/data_clean/sentiment_ua.csv\", delimiter=\";\")\n",
    "lexicon_df.columns = lexicon_df.columns.str.strip().str.replace('\\ufeff', '')\n",
    "print(lexicon_df.columns.tolist())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:32.944710Z",
     "start_time": "2025-09-09T13:57:32.924401Z"
    }
   },
   "id": "41614ba09423e806"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "lexicon = dict(zip(lexicon_df[\"word\"], lexicon_df[\"pos_neg\"]))\n",
    "# Simple sentiment scorer\n",
    "def score_comment(text):\n",
    "    score = 0\n",
    "    words = text.lower().split()  # crude tokenization\n",
    "    for word in words:\n",
    "        score += lexicon.get(word, 0)\n",
    "    return score\n",
    "\n",
    "\n",
    "# Classifier based on score\n",
    "def classify_sentiment(score):\n",
    "    if score > 0:\n",
    "        return \"positive\"  # 1\n",
    "    elif score < 0:\n",
    "        return \"negative\"  # -1\n",
    "    else:\n",
    "        return \"neutral\"  # 0\n",
    "\n",
    "\n",
    "# Applying to Ukrainian comments only\n",
    "ukr_comments = df_all[df_all[\"comment_language\"] == \"uk\"].copy()\n",
    "ukr_comments[\"ua_sentiment_score\"] = ukr_comments[\"text_transformed\"].apply(score_comment)\n",
    "ukr_comments[\"ua_sentiment_label\"] = ukr_comments[\"ua_sentiment_score\"].apply(classify_sentiment)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:32.977815Z",
     "start_time": "2025-09-09T13:57:32.947851Z"
    }
   },
   "id": "7e87ff520001ad13"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        text_transformed  ua_sentiment_score  \\\n",
      "8294   я б не рекомендувала поки повзти в сторону\\nпо...                  -2   \n",
      "9375   політичний дрес-код:rolling_on_the_floor_laugh...                   0   \n",
      "768    шановний отто . у єс єдина армія що має досвід...                   3   \n",
      "16119  ні, дякую, ти не в трамваї і не в військоматі....                   0   \n",
      "14480  як їм усім весело \\nпоки по нашій країні летят...                  -2   \n",
      "15728  а чо в нього єблет такий незадоволений сука ст...                   0   \n",
      "3172   немає за що вибачатись.захід прогнив до дна,це...                   0   \n",
      "837    як \"президент\" може \"непублічно\"протестувати ?...                   0   \n",
      "16066  гіга-потужно, хочу ще:face_with_tears_of_joy :...                   0   \n",
      "12271  зеленський лети в китай на зустріч з сін цен п...                   0   \n",
      "14069              зеля тримайся ми з тобою:raised_fist                    0   \n",
      "6235                              шо ти там тяфкаєш дура                   0   \n",
      "14936   а через пів години напишуть,що не так переклали!                   0   \n",
      "5705   ви три роки приїзджали дивились на кров наших ...                  -2   \n",
      "4745                                є оригінал в когось?                   0   \n",
      "1326   з демократами таке саме. жували б соплі, розка...                  -1   \n",
      "587            це аналітика, а куколд тут тільки ти сам.                   0   \n",
      "1588   який жарт . точно син зеленського один в один ...                  -2   \n",
      "9887   я думаю цей чорт в змозі і на два хуя стрибнут...                  -1   \n",
      "7785                              хай рижий локті кусає.                   0   \n",
      "\n",
      "      ua_sentiment_label  \n",
      "8294            negative  \n",
      "9375             neutral  \n",
      "768             positive  \n",
      "16119            neutral  \n",
      "14480           negative  \n",
      "15728            neutral  \n",
      "3172             neutral  \n",
      "837              neutral  \n",
      "16066            neutral  \n",
      "12271            neutral  \n",
      "14069            neutral  \n",
      "6235             neutral  \n",
      "14936            neutral  \n",
      "5705            negative  \n",
      "4745             neutral  \n",
      "1326            negative  \n",
      "587              neutral  \n",
      "1588            negative  \n",
      "9887            negative  \n",
      "7785             neutral  \n"
     ]
    }
   ],
   "source": [
    "print(ukr_comments[[\"text_transformed\", \"ua_sentiment_score\", \"ua_sentiment_label\"]].sample(20, random_state=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:32.989972Z",
     "start_time": "2025-09-09T13:57:32.979879Z"
    }
   },
   "id": "7003273a53e022c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing two models:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63f82bb1b78e5432"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Sample 100 Ukrainian comments\n",
    "ukr_sample = ukr_comments.sample(100, random_state=42).copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:32.995298Z",
     "start_time": "2025-09-09T13:57:32.989Z"
    }
   },
   "id": "ca6c5152e8a48c81"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ukr_sample[\"ua_sentiment_score\"] = ukr_sample[\"text_transformed\"].apply(score_comment)\n",
    "ukr_sample[\"lexicon_sentiment_label\"] = ukr_sample[\"ua_sentiment_score\"].apply(classify_sentiment)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:32.997777Z",
     "start_time": "2025-09-09T13:57:32.992599Z"
    }
   },
   "id": "2ee20d0282c30260"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "ukr_sample[\"rubert_sentiment_label\"] = predict_sentiment_ua(ukr_sample[\"text_transformed\"].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:56.302031Z",
     "start_time": "2025-09-09T13:57:32.996299Z"
    }
   },
   "id": "36a27e2de35d8673"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement rate: 0.18\n",
      "rubert_sentiment_label   negative  neutral  positive\n",
      "lexicon_sentiment_label                             \n",
      "negative                        2        0         7\n",
      "neutral                        27        5        43\n",
      "positive                        3        2        11\n"
     ]
    }
   ],
   "source": [
    "# Count agreement and disagreements\n",
    "ukr_sample[\"agree\"] = ukr_sample[\"lexicon_sentiment_label\"] == ukr_sample[\"rubert_sentiment_label\"]\n",
    "print(\"Agreement rate:\", ukr_sample[\"agree\"].mean())\n",
    "\n",
    "# Confusion matrix-like view\n",
    "comparison = ukr_sample.groupby([\"lexicon_sentiment_label\", \"rubert_sentiment_label\"]).size().unstack(fill_value=0)\n",
    "print(comparison)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:56.353811Z",
     "start_time": "2025-09-09T13:57:56.305020Z"
    }
   },
   "id": "bf61e095ffbe42c9"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating confusion matrix again (in case it's not in memory)\n",
    "comparison = ukr_sample.groupby(\n",
    "    [\"lexicon_sentiment_label\", \"rubert_sentiment_label\"]\n",
    ").size().unstack(fill_value=0)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(comparison, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix: Lexicon vs RoBERTa Sentiment Labels\")\n",
    "plt.xlabel(\"RoBERTa Sentiment\")\n",
    "plt.ylabel(\"Lexicon Sentiment\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:56.817825Z",
     "start_time": "2025-09-09T13:57:56.361233Z"
    }
   },
   "id": "b292814e2c641a01"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXT: китай теж не дурний, але трамп робить, що робить, а саме \"купляє\" собі союзників, або хоча б нейтралів у теоретичній війні.:man_shrugging_selector \n",
      "LEXICON: neutral | RoBERTa: positive\n",
      "\n",
      "TEXT: я б не витримав й хвилини :pig_face \n",
      "LEXICON: neutral | RoBERTa: positive\n",
      "\n",
      "TEXT: а може це треба зробити до путіна? таке враження що це українці напали на рф. :pouting_face \n",
      "LEXICON: neutral | RoBERTa: positive\n",
      "\n",
      "TEXT: сталін костюми не носив, наприклад\n",
      "LEXICON: neutral | RoBERTa: positive\n",
      "\n",
      "TEXT: мага буде теперь купляти візу до києва!!!! наступні перемовини в бучі !!!\n",
      "LEXICON: neutral | RoBERTa: positive\n"
     ]
    }
   ],
   "source": [
    "# Filtering such mismatches\n",
    "mismatch_df = ukr_sample[\n",
    "    (ukr_sample[\"lexicon_sentiment_label\"] == \"neutral\") &\n",
    "    (ukr_sample[\"rubert_sentiment_label\"] == \"positive\")\n",
    "    ]\n",
    "\n",
    "# Showing sample mismatches\n",
    "for idx, row in mismatch_df.head(5).iterrows():\n",
    "    print(f\"\\nTEXT: {row['text_transformed']}\")\n",
    "    print(f\"LEXICON: {row['lexicon_sentiment_label']} | RoBERTa: {row['rubert_sentiment_label']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T13:57:56.846512Z",
     "start_time": "2025-09-09T13:57:56.826521Z"
    }
   },
   "id": "10df5c67f36c4812"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def predict_sentiment_ua(texts):\n",
    "    inputs = tokenizer_ua(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ua(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = torch.argmax(probs, dim=1)\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    return [labels[i] for i in predictions]\n",
    "\n",
    "\n",
    "def batch_predict_sentiment(texts, batch_size=100):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        preds = predict_sentiment_ua(batch)\n",
    "        results.extend(preds)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Ukrainian comments\n",
    "ukr_comments = df_all[df_all[\"comment_language\"] == \"uk\"].copy()\n",
    "ukr_comments = ukr_comments.reset_index(drop=True)\n",
    "\n",
    "# Applying RoBERTa model in batches\n",
    "ukr_comments[\"rubert_sentiment_label\"] = batch_predict_sentiment(\n",
    "    ukr_comments[\"text_transformed\"].tolist(), batch_size=100\n",
    ")\n",
    "\n",
    "# Russian comments\n",
    "ru_comments = df_all[df_all[\"comment_language\"] == \"ru\"].copy()\n",
    "ru_comments = ru_comments.reset_index(drop=True)\n",
    "\n",
    "ru_comments[\"rubert_sentiment_label\"] = batch_predict_sentiment(\n",
    "    ru_comments[\"text_transformed\"].tolist(), batch_size=100\n",
    ")\n",
    "\n",
    "# Combining both back together if needed\n",
    "df_roberta_labeled = pd.concat([ukr_comments, ru_comments], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-09T14:20:55.823698Z"
    }
   },
   "id": "6518190544fa3d7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save to file\n",
    "df_roberta_labeled.to_csv(\"data_clean/comments_labeled_roberta.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73328b8e3587016c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to compare how good the RoBERT model works, I am labeleing a sample on my own and checking with the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b05b9edbff110089"
  },
  {
   "cell_type": "markdown",
   "source": [
    "df_roberta_labeled.to_excel(\"data_clean/comments_labeled_roberta.xlsx\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc6ef6cd91a2aa35"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "       post_id                                       comment_text  \\\n0        21390  ти антисеміт!!!ти гітлера підтримуєш???\\nце як...   \n1        21390  тобто не посилати гроші в ізраїль, бо бідним а...   \n2        21390            сторіс, рілс, шортс, тік-ток на шевроні   \n3        21390                    іноземний легіон бригади монако   \n4        21390           треба ще монету з диваном\\nв честь венса   \n...        ...                                                ...   \n31515    93453  земли - россии 🇷🇺\\nдолги - европе 🇪🇺\\nденьги -...   \n31516    93453  быть друзьями россии и быть с россией на равны...   \n31517    93453  50%? америкосы заберут 150,в этом сомневаться ...   \n31518    93453                                  доня агент кремля   \n31519    93453  ого, пареце, что сша и украина до сих пор не м...   \n\n              comment_date  comment_user_id channel_orientation  \\\n0      2025-03-02 10:10:15     7.868621e+09       pro-ukrainian   \n1      2025-03-02 10:08:18     7.868621e+09       pro-ukrainian   \n2      2025-03-02 00:34:14     5.951120e+08       pro-ukrainian   \n3      2025-03-02 00:33:00     5.951120e+08       pro-ukrainian   \n4      2025-03-02 00:31:56     2.765382e+08       pro-ukrainian   \n...                    ...              ...                 ...   \n31515  2025-02-26 15:41:55     5.057871e+08         pro-russian   \n31516  2025-02-26 15:41:24     5.203758e+09         pro-russian   \n31517  2025-02-26 15:39:35     5.169864e+09         pro-russian   \n31518  2025-02-26 15:38:56     2.033804e+09         pro-russian   \n31519  2025-02-26 15:38:55     7.454295e+09         pro-russian   \n\n                   source_file comment_language  \\\n0      data/ua/Comments_ds.csv               uk   \n1      data/ua/Comments_ds.csv               uk   \n2      data/ua/Comments_ds.csv               uk   \n3      data/ua/Comments_ds.csv               uk   \n4      data/ua/Comments_ds.csv               uk   \n...                        ...              ...   \n31515  data/ru/Comments_re.csv               ru   \n31516  data/ru/Comments_re.csv               ru   \n31517  data/ru/Comments_re.csv               ru   \n31518  data/ru/Comments_re.csv               ru   \n31519  data/ru/Comments_re.csv               ru   \n\n                                        text_transformed                 date  \\\n0      ти антисеміт!!!ти гітлера підтримуєш???\\nце як...  2025-02-28 20:20:56   \n1      тобто не посилати гроші в ізраїль, бо бідним а...  2025-02-28 20:20:56   \n2                сторіс, рілс, шортс, тік-ток на шевроні  2025-02-28 20:20:56   \n3                        іноземний легіон бригади монако  2025-02-28 20:20:56   \n4               треба ще монету з диваном\\nв честь венса  2025-02-28 20:20:56   \n...                                                  ...                  ...   \n31515  земли - россии :Russia \\nдолги - европе :Europ...  2025-02-26 15:37:46   \n31516  быть друзьями россии и быть с россией на равны...  2025-02-26 15:37:46   \n31517  50%? америкосы заберут 150,в этом сомневаться ...  2025-02-26 15:37:46   \n31518                                  доня агент кремля  2025-02-26 15:37:46   \n31519  ого, пареце, что сша и украина до сих пор не м...  2025-02-26 15:37:46   \n\n        views  forwards     channel_id  channel_name source           bloc  \\\n0      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n1      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n2      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n3      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n4      441866      1146 -1001469021333   DeepStateUA     ds  pro-ukrainian   \n...       ...       ...            ...           ...    ...            ...   \n31515  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n31516  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n31517  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n31518  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n31519  397626      1383 -1001260622817  readovkanews     re    pro-russian   \n\n      period  post_age_at_comment rubert_sentiment_label manual_label  \n0       post            37.821944               positive     negative  \n1       post            37.789444               positive     negative  \n2       post            28.221667               negative      neutral  \n3       post            28.201111               positive      neutral  \n4       post            28.183333               negative      neutral  \n...      ...                  ...                    ...          ...  \n31515    pre             0.069167               positive          NaN  \n31516    pre             0.060556               positive          NaN  \n31517    pre             0.030278               negative          NaN  \n31518    pre             0.019444               negative          NaN  \n31519    pre             0.019167               positive          NaN  \n\n[31520 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>post_id</th>\n      <th>comment_text</th>\n      <th>comment_date</th>\n      <th>comment_user_id</th>\n      <th>channel_orientation</th>\n      <th>source_file</th>\n      <th>comment_language</th>\n      <th>text_transformed</th>\n      <th>date</th>\n      <th>views</th>\n      <th>forwards</th>\n      <th>channel_id</th>\n      <th>channel_name</th>\n      <th>source</th>\n      <th>bloc</th>\n      <th>period</th>\n      <th>post_age_at_comment</th>\n      <th>rubert_sentiment_label</th>\n      <th>manual_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21390</td>\n      <td>ти антисеміт!!!ти гітлера підтримуєш???\\nце як...</td>\n      <td>2025-03-02 10:10:15</td>\n      <td>7.868621e+09</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>uk</td>\n      <td>ти антисеміт!!!ти гітлера підтримуєш???\\nце як...</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>37.821944</td>\n      <td>positive</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21390</td>\n      <td>тобто не посилати гроші в ізраїль, бо бідним а...</td>\n      <td>2025-03-02 10:08:18</td>\n      <td>7.868621e+09</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>uk</td>\n      <td>тобто не посилати гроші в ізраїль, бо бідним а...</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>37.789444</td>\n      <td>positive</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21390</td>\n      <td>сторіс, рілс, шортс, тік-ток на шевроні</td>\n      <td>2025-03-02 00:34:14</td>\n      <td>5.951120e+08</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>uk</td>\n      <td>сторіс, рілс, шортс, тік-ток на шевроні</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>28.221667</td>\n      <td>negative</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21390</td>\n      <td>іноземний легіон бригади монако</td>\n      <td>2025-03-02 00:33:00</td>\n      <td>5.951120e+08</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>uk</td>\n      <td>іноземний легіон бригади монако</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>28.201111</td>\n      <td>positive</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21390</td>\n      <td>треба ще монету з диваном\\nв честь венса</td>\n      <td>2025-03-02 00:31:56</td>\n      <td>2.765382e+08</td>\n      <td>pro-ukrainian</td>\n      <td>data/ua/Comments_ds.csv</td>\n      <td>uk</td>\n      <td>треба ще монету з диваном\\nв честь венса</td>\n      <td>2025-02-28 20:20:56</td>\n      <td>441866</td>\n      <td>1146</td>\n      <td>-1001469021333</td>\n      <td>DeepStateUA</td>\n      <td>ds</td>\n      <td>pro-ukrainian</td>\n      <td>post</td>\n      <td>28.183333</td>\n      <td>negative</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31515</th>\n      <td>93453</td>\n      <td>земли - россии 🇷🇺\\nдолги - европе 🇪🇺\\nденьги -...</td>\n      <td>2025-02-26 15:41:55</td>\n      <td>5.057871e+08</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>земли - россии :Russia \\nдолги - европе :Europ...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.069167</td>\n      <td>positive</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31516</th>\n      <td>93453</td>\n      <td>быть друзьями россии и быть с россией на равны...</td>\n      <td>2025-02-26 15:41:24</td>\n      <td>5.203758e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>быть друзьями россии и быть с россией на равны...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.060556</td>\n      <td>positive</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31517</th>\n      <td>93453</td>\n      <td>50%? америкосы заберут 150,в этом сомневаться ...</td>\n      <td>2025-02-26 15:39:35</td>\n      <td>5.169864e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>50%? америкосы заберут 150,в этом сомневаться ...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.030278</td>\n      <td>negative</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31518</th>\n      <td>93453</td>\n      <td>доня агент кремля</td>\n      <td>2025-02-26 15:38:56</td>\n      <td>2.033804e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>доня агент кремля</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.019444</td>\n      <td>negative</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31519</th>\n      <td>93453</td>\n      <td>ого, пареце, что сша и украина до сих пор не м...</td>\n      <td>2025-02-26 15:38:55</td>\n      <td>7.454295e+09</td>\n      <td>pro-russian</td>\n      <td>data/ru/Comments_re.csv</td>\n      <td>ru</td>\n      <td>ого, пареце, что сша и украина до сих пор не м...</td>\n      <td>2025-02-26 15:37:46</td>\n      <td>397626</td>\n      <td>1383</td>\n      <td>-1001260622817</td>\n      <td>readovkanews</td>\n      <td>re</td>\n      <td>pro-russian</td>\n      <td>pre</td>\n      <td>0.019167</td>\n      <td>positive</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>31520 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled = pd.read_csv(\"data/data_clean/comments_labeled_manual.csv\")\n",
    "df_labeled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:12.054133Z",
     "start_time": "2025-09-09T14:21:11.795094Z"
    }
   },
   "id": "7abf070495d289f4"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "valid_labels = {\"positive\", \"neutral\", \"negative\"}\n",
    "\n",
    "labeled_subset = df_labeled[\n",
    "    df_labeled[\"manual_label\"].isin(valid_labels) &\n",
    "    df_labeled[\"text_transformed\"].notna() &\n",
    "    (df_labeled[\"text_transformed\"].str.strip() != \"\")\n",
    "].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:12.092236Z",
     "start_time": "2025-09-09T14:21:12.056985Z"
    }
   },
   "id": "216568ae7d130e75"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique manual labels: ['negative' 'neutral' 'positive' nan]\n",
      "Missing text rows: 0\n",
      "Empty text rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique manual labels:\", df_labeled[\"manual_label\"].unique())\n",
    "print(\"Missing text rows:\", df_labeled[\"text_transformed\"].isna().sum())\n",
    "print(\"Empty text rows:\", (df_labeled[\"text_transformed\"].str.strip() == \"\").sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:13.151101Z",
     "start_time": "2025-09-09T14:21:13.019925Z"
    }
   },
   "id": "24cca5006b7051cc"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rubert_sentiment_label  negative  neutral  positive\n",
      "manual_label                                       \n",
      "negative                     146       19       202\n",
      "neutral                       53       29        72\n",
      "positive                       7        7        64\n"
     ]
    }
   ],
   "source": [
    "confusion = labeled_subset.groupby([\"manual_label\", \"rubert_sentiment_label\"]).size().unstack(fill_value=0)\n",
    "print(confusion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:13.853586Z",
     "start_time": "2025-09-09T14:21:13.819375Z"
    }
   },
   "id": "1703c4e1a6ce5b50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "RoBERTa is strongly biased toward \"positive\"\n",
    "Here we can see 202 comments, which I labeled as negative, but RoBERTa called positive.\n",
    "\n",
    "Even for neutral, it labeled 72 as positive.\n",
    "\n",
    "Suggests the model tends to underestimate criticism, sarcasm, and subtle hostility — likely due to being trained on more standard corpora or Russian social media with different tone norms."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40dc0c7216b92bb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tunig the Rubert model for my dataset:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a45cc68d55884c3b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Forcing PyTorch to use CPU instead of MPS/GPU\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:15.173787Z",
     "start_time": "2025-09-09T14:21:15.156782Z"
    }
   },
   "id": "bb6b0e2aaf799fa2"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Step 3: Apply label mapping\n",
    "labeled_subset[\"label\"] = labeled_subset[\"manual_label\"].map(label2id).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:15.403473Z",
     "start_time": "2025-09-09T14:21:15.386243Z"
    }
   },
   "id": "ee7768c8aee0b521"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(labeled_subset[[\"text_transformed\", \"label\"]])\n",
    "dataset = dataset.rename_columns({\"text_transformed\": \"text\"})\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:15.815307Z",
     "start_time": "2025-09-09T14:21:15.706005Z"
    }
   },
   "id": "cd405c4d6d152ef7"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    " # Loading tockenizer\n",
    "model_name = \"cointegrated/rubert-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:16.252690Z",
     "start_time": "2025-09-09T14:21:15.932175Z"
    }
   },
   "id": "7b5c97838f24ee57"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/479 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa07d87762d24d47a2f6ea6a7b1e07a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/120 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "900d05c958ae4c2bb52f52ca91bbdc19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizing\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:16.848298Z",
     "start_time": "2025-09-09T14:21:16.250945Z"
    }
   },
   "id": "356575804fae1c77"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/479 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "200282058f1c4f14ae97a807b0027cc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/120 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ccfa677215647879ec85bea9e4aef62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = tokenized.map(lambda batch: {\"label\": [int(label) for label in batch[\"label\"]]}, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:16.885611Z",
     "start_time": "2025-09-09T14:21:16.848080Z"
    }
   },
   "id": "819bf37d12f2e855"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(tokenized[\"train\"][0][\"label\"], type(tokenized[\"train\"][0][\"label\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:18.343877Z",
     "start_time": "2025-09-09T14:21:18.316753Z"
    }
   },
   "id": "31ed73a2f231ca23"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n      (position_embeddings): Embedding(512, 312)\n      (token_type_embeddings): Embedding(2, 312)\n      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-2): 3 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=312, out_features=312, bias=True)\n              (key): Linear(in_features=312, out_features=312, bias=True)\n              (value): Linear(in_features=312, out_features=312, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=312, out_features=312, bias=True)\n              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=312, out_features=600, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=600, out_features=312, bias=True)\n            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=312, out_features=312, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=312, out_features=3, bias=True)\n)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
    "    label2id={\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    ")\n",
    "model.to(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:18.873537Z",
     "start_time": "2025-09-09T14:21:18.561488Z"
    }
   },
   "id": "cfa9c586f931f3fa"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1509: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:18.910791Z",
     "start_time": "2025-09-09T14:21:18.873811Z"
    }
   },
   "id": "8f30a809c58f6d2d"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:19.209297Z",
     "start_time": "2025-09-09T14:21:19.184994Z"
    }
   },
   "id": "419a8fe32dea0d0f"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:21:19.464645Z",
     "start_time": "2025-09-09T14:21:19.432623Z"
    }
   },
   "id": "298e776abe12f510"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/440 : < :, Epoch 0.01/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=440, training_loss=0.6561759255149148, metrics={'train_runtime': 401.6843, 'train_samples_per_second': 8.763, 'train_steps_per_second': 1.095, 'total_flos': 25960593162240.0, 'train_loss': 0.6561759255149148, 'epoch': 4.0})"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:38:16.681987Z",
     "start_time": "2025-09-09T14:31:34.953906Z"
    }
   },
   "id": "e57dbe506fa55ceb"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "('rubert-sentiment-finetuned/tokenizer_config.json',\n 'rubert-sentiment-finetuned/special_tokens_map.json',\n 'rubert-sentiment-finetuned/vocab.txt',\n 'rubert-sentiment-finetuned/added_tokens.json',\n 'rubert-sentiment-finetuned/tokenizer.json')"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "trainer.save_model(\"models/rubert-sentiment-finetuned\")\n",
    "tokenizer.save_pretrained(\"models/rubert-sentiment-finetuned\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:25:14.728561Z",
     "start_time": "2025-09-09T14:25:14.664088Z"
    }
   },
   "id": "848eee904ee5b293"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/15 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.86458820104599,\n 'eval_runtime': 1.4627,\n 'eval_samples_per_second': 82.037,\n 'eval_steps_per_second': 10.255,\n 'epoch': 4.0}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:25:16.193268Z",
     "start_time": "2025-09-09T14:25:14.726252Z"
    }
   },
   "id": "fc049ea1a8bcc870"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[{'label': 'negative', 'score': 0.1617555320262909},\n  {'label': 'neutral', 'score': 0.46368080377578735},\n  {'label': 'positive', 'score': 0.37456363439559937}]]"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "pipeline(\"Це справжній успіх для нашої країни.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:40.211974Z",
     "start_time": "2025-09-09T14:47:40.095459Z"
    }
   },
   "id": "85ed468bfcb36e76"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    " def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1_macro\": f1_score(labels, predictions, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, predictions, average=\"weighted\"),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:42.822173Z",
     "start_time": "2025-09-09T14:47:42.798842Z"
    }
   },
   "id": "e9e116844bdad971"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:43.776932Z",
     "start_time": "2025-09-09T14:47:43.699080Z"
    }
   },
   "id": "618a7f01320fa97"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:44.141147Z",
     "start_time": "2025-09-09T14:47:44.125710Z"
    }
   },
   "id": "3bd2b34f26c8f406"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Це справжній успіх для нашої країни. → neutral (0.46)\n",
      "Це ганьба! → positive (0.71)\n",
      "Нічого не сталося. → negative (0.53)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Це справжній успіх для нашої країни.\",\n",
    "    \"Це ганьба!\",\n",
    "    \"Нічого не сталося.\",\n",
    "]\n",
    "\n",
    "results = pipeline(texts)\n",
    "for text, prediction in zip(texts, results):\n",
    "    print(f\"{text} → {prediction[0]['label']} ({prediction[0]['score']:.2f})\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:44.918598Z",
     "start_time": "2025-09-09T14:47:44.874082Z"
    }
   },
   "id": "bfd3c15699878463"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Splitting by class\n",
    "neg = df_labeled[df_labeled[\"manual_label\"] == \"negative\"]\n",
    "neu = df_labeled[df_labeled[\"manual_label\"] == \"neutral\"]\n",
    "pos = df_labeled[df_labeled[\"manual_label\"] == \"positive\"]\n",
    "\n",
    "# Upsample minority classes\n",
    "neu_upsampled = resample(neu, replace=True, n_samples=len(neg), random_state=42)\n",
    "pos_upsampled = resample(pos, replace=True, n_samples=len(neg), random_state=42)\n",
    "\n",
    "# Combining into balanced set\n",
    "df_balanced = pd.concat([neg, neu_upsampled, pos_upsampled])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:45.626567Z",
     "start_time": "2025-09-09T14:47:45.591266Z"
    }
   },
   "id": "bc6deb74e4756964"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "negative    367\nneutral     154\npositive     78\nName: manual_label, dtype: int64"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled[\"manual_label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:47.147779Z",
     "start_time": "2025-09-09T14:47:47.133091Z"
    }
   },
   "id": "8c256f3ba4a8db1e"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Separating by class\n",
    "neg = df_labeled[df_labeled[\"manual_label\"] == \"negative\"]\n",
    "neu = df_labeled[df_labeled[\"manual_label\"] == \"neutral\"]\n",
    "pos = df_labeled[df_labeled[\"manual_label\"] == \"positive\"]\n",
    "\n",
    "# Getting the size of the largest class\n",
    "max_size = max(len(neg), len(neu), len(pos))\n",
    "\n",
    "# Upsampling each class to match max_size\n",
    "neg_up = resample(neg, replace=True, n_samples=max_size, random_state=42)\n",
    "neu_up = resample(neu, replace=True, n_samples=max_size, random_state=42)\n",
    "pos_up = resample(pos, replace=True, n_samples=max_size, random_state=42)\n",
    "\n",
    "# Combining into one DataFrame\n",
    "df_balanced = pd.concat([neg_up, neu_up, pos_up]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:47.323283Z",
     "start_time": "2025-09-09T14:47:47.307741Z"
    }
   },
   "id": "74a03380d84dc09f"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "df_balanced[\"label\"] = df_balanced[\"manual_label\"].map(label2id).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:48.137049Z",
     "start_time": "2025-09-09T14:47:48.112582Z"
    }
   },
   "id": "45ae718220b1f76f"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Dropping missing/blank rows\n",
    "df_balanced = df_balanced[df_balanced[\"text_transformed\"].notna()]\n",
    "df_balanced = df_balanced[df_balanced[\"text_transformed\"].str.strip() != \"\"]\n",
    "\n",
    "# Renaming and select only relevant columns\n",
    "df_ready = df_balanced[[\"text_transformed\", \"label\"]].rename(columns={\"text_transformed\": \"text\"})\n",
    "\n",
    "# Converting to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df_ready)\n",
    "\n",
    "# Train-test split\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:48.505128Z",
     "start_time": "2025-09-09T14:47:48.451173Z"
    }
   },
   "id": "c75107e329c7578e"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    " # Loading tockenizer\n",
    "model_name = \"cointegrated/rubert-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:49.292751Z",
     "start_time": "2025-09-09T14:47:48.994833Z"
    }
   },
   "id": "4d3a501b5a310b56"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/880 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93153108d2cd4502b6d2d24c6f9aa73a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/221 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbaa63073f6543d291ee78869de84594"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizing\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:49.563542Z",
     "start_time": "2025-09-09T14:47:49.298320Z"
    }
   },
   "id": "4fe379b55656306c"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/880 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "803352b118b44189a18574f9f86c7e65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/221 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ede954eab484cf0b2c8de4e71c60820"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = tokenized.map(lambda batch: {\"label\": [int(label) for label in batch[\"label\"]]}, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:49.590236Z",
     "start_time": "2025-09-09T14:47:49.563896Z"
    }
   },
   "id": "f2fb778e9cb64da2"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n      (position_embeddings): Embedding(512, 312)\n      (token_type_embeddings): Embedding(2, 312)\n      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-2): 3 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=312, out_features=312, bias=True)\n              (key): Linear(in_features=312, out_features=312, bias=True)\n              (value): Linear(in_features=312, out_features=312, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=312, out_features=312, bias=True)\n              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=312, out_features=600, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=600, out_features=312, bias=True)\n            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=312, out_features=312, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=312, out_features=3, bias=True)\n)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
    "    label2id={\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    ")\n",
    "model.to(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T14:47:50.363490Z",
     "start_time": "2025-09-09T14:47:50.107985Z"
    }
   },
   "id": "1bae5acaf9f5f3bd"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1_macro\": f1_score(labels, predictions, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, predictions, average=\"weighted\"),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-13T08:58:58.181853Z",
     "start_time": "2025-09-13T08:58:58.162242Z"
    }
   },
   "id": "560b05eb69543368"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1509: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-13T08:58:58.806190Z",
     "start_time": "2025-09-13T08:58:58.769256Z"
    }
   },
   "id": "84accd0d98a18d81"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-13T08:58:59.749161Z",
     "start_time": "2025-09-13T08:58:59.609239Z"
    }
   },
   "id": "953dcac2d7024236"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/440 : < :, Epoch 0.01/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=440, training_loss=0.6662392356178978, metrics={'train_runtime': 384.0855, 'train_samples_per_second': 9.165, 'train_steps_per_second': 1.146, 'total_flos': 25960593162240.0, 'train_loss': 0.6662392356178978, 'epoch': 4.0})"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-13T09:05:26.028238Z",
     "start_time": "2025-09-13T08:59:01.922820Z"
    }
   },
   "id": "3386c9124f67fac3"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[{'label': 'negative', 'score': 0.1572302281856537},\n  {'label': 'neutral', 'score': 0.4842468500137329},\n  {'label': 'positive', 'score': 0.3585229218006134}]]"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "pipeline(\"Це справжній успіх для нашої країни.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-13T09:05:26.172033Z",
     "start_time": "2025-09-13T09:05:26.033695Z"
    }
   },
   "id": "937d15e4c187bad8"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/28 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6527784466743469, 'eval_accuracy': 0.746606334841629, 'eval_f1_macro': 0.7462703680021168, 'eval_f1_weighted': 0.7468782889935391}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print({k: v for k, v in results.items() if k in [\"eval_loss\",\"eval_accuracy\",\"eval_f1_macro\",\"eval_f1_weighted\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-13T09:05:27.664637Z",
     "start_time": "2025-09-13T09:05:26.055394Z"
    }
   },
   "id": "a7e7029e5bacf457"
  },
  {
   "cell_type": "raw",
   "source": [
    "# Saving the new trained model\n",
    "model.save_pretrained(\"models/rubert-finetuned-v2\")\n",
    "tokenizer.save_pretrained(\"models/rubert-finetuned-v2\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b56d6a1a16cffe0b"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a31fc8654382fa70e01b8b1b084ed875bc80468ef06668984d01fe98600013e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
